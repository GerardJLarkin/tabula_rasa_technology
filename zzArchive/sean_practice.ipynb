{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add ignore warnings for now, will remove and debug once full algorithm is complete\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## import packages/libraries\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from itertools import product\n",
    "import sys\n",
    "import sqlite3\n",
    "\n",
    "## append filepath to allow files to be called from within project folder\n",
    "sys.path.append('/home/gerard/Desktop/capstone_project/patoms')\n",
    "sys.path.append('/home/gerard/Desktop/capstone_project')\n",
    "\n",
    "## call locally created functions\n",
    "from snapshot_2d_pattern_v2 import patoms2d\n",
    "from snapshot_3d_pattern_v6 import patoms3d\n",
    "from pattern_2d_compare_v2 import pattern_compare_2d\n",
    "from pattern_3d_compare_v4 import pattern_compare_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start timer to asses how long process takes\n",
    "s = perf_counter()\n",
    "\n",
    "## save 2D patterns to database and compare new patterns to existing patterns\n",
    "con2d = sqlite3.connect(\"database_2d.db\")\n",
    "cur2d = con2d.cursor()\n",
    "\n",
    "## create test data for algorithm development\n",
    "np.random.seed(42)\n",
    "rand_array = np.random.random((1, 720, 1280))\n",
    "z_len = rand_array.shape[0]\n",
    "y_len = rand_array.shape[1]\n",
    "x_len = rand_array.shape[2]\n",
    "\n",
    "dist_sim_threshold = 0.85\n",
    "centroid_sim_threshold_x = 0.85\n",
    "centroid_sim_threshold_y = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function merge lists with common elements\n",
    "def merge_lists_with_common_elements(nested_lists):\n",
    "    result = []  # To store merged lists\n",
    "\n",
    "    for sublist in nested_lists:\n",
    "        # Check if this sublist overlaps with any list in the result\n",
    "        for merged_list in result:\n",
    "            if set(sublist) & set(merged_list):  # Common elements exist\n",
    "                merged_list.extend(sublist)  # Add all elements\n",
    "                merged_list[:] = list(set(merged_list))  # Remove duplicates\n",
    "                break\n",
    "        else:\n",
    "            # If no overlap found, add the sublist as a new group\n",
    "            result.append(sublist[:])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get 2D patterns with multiprocessing (secs): 0.3625822459871415\n",
      "Time to get 2D patterns with multiprocessing (secs): 0.35410050899372436\n"
     ]
    }
   ],
   "source": [
    "# ingest data frame by frame\n",
    "for frame in range(rand_array.shape[0]):\n",
    "    #################################################################################\n",
    "    ####################### FIRST TASK: FIND PATTERNS IN FRAME ######################\n",
    "    #################################################################################\n",
    "    similar_pattern_groups_list_new = []\n",
    "    # find patterns in data\n",
    "    frame_patoms = patoms2d(x_len, y_len, rand_array[frame,:,:], frame)\n",
    "    # patom = [[norm_x, norm_y], [pattern_centroid_x, pattern_centroid_y], patom_ind, frame_ind, patom_time]\n",
    "    # patom[i][[0][0]: list of x_pos, patom[i][[0][1]: list of y_pos, patom[i][[1][0]: x_cent, patom[i][[1][1]: y_cent, patom[i][[2]: patom_ind, patom[i][[3]: frame_ind, patom[i][[4]: patom_time,\n",
    "    num_patoms = len(frame_patoms)\n",
    "    #################################################################################\n",
    "    ########## SECOND TASK: COMPARE ALL PATTERNS IN FRAME TO THEMSELVES ############# -- might not be needed in future iterations but lets see\n",
    "    #################################################################################\n",
    "    ## compare all patoms against all other patoms in the frame, add to list that can hold patoms before comparing against exiting patoms\n",
    "    atime = perf_counter()\n",
    "    patom_indexes = list(product(range(num_patoms), range(num_patoms)))\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        items = [(frame_patoms[i[0]][0], frame_patoms[i[0]][1], frame_patoms[i[1]][0], frame_patoms[i[1]][1]) for i in patom_indexes]\n",
    "        ## function outputs ind value of the patom_indexes list, the centroid and distance similarity measures\n",
    "        res = pool.starmap(pattern_compare_2d, items)\n",
    "        # res output: [1.0, (0.05407046509274386, 0.03361332388786884)]\n",
    "        #print(\"Time to compare 2D patterns with multiprocessing (secs):\", (perf_counter()-atime))\n",
    "        # create list the holds the index of each patom identified in the frame that are similar to one another\n",
    "        match_list_new = []\n",
    "        ## loop through the output of the comparison function\n",
    "        for ix, i in enumerate(res):\n",
    "            ## pass if its the same patom in the frame being compared against itself\n",
    "            if patom_indexes[ix][0] == patom_indexes[ix][1]:\n",
    "                pass\n",
    "            else:\n",
    "                ## check if compared patterns fall within similarity threshold values\n",
    "                if (i[1][0] >= centroid_sim_threshold_x) and (i[1][1] >= centroid_sim_threshold_y) and (i[0] >= dist_sim_threshold):\n",
    "                    match_list_new.append([patom_indexes[ix][0], patom_indexes[ix][1]])\n",
    "                else:\n",
    "                    pass\n",
    "        # merge pattern indices that have similar elements\n",
    "        if match_list_new:\n",
    "            similar_pattern_groups = merge_lists_with_common_elements(match_list_new)\n",
    "            similar_pattern_groups_list_new.append(similar_pattern_groups)\n",
    "        else:\n",
    "            pass\n",
    "    # add similar pattern groups back to the original patom list and only keep distinct patterns\n",
    "    # flatten group list to get patoms that are similar, then compare against oirignal patom list to get those patoms not in the grouped list\n",
    "    # create 'average' ref pattern for patterns in similar groups\n",
    "    if similar_pattern_groups_list_new:\n",
    "        flat_groups = [xs for x in similar_pattern_groups_list_new for xs in x]\n",
    "        remaining_patoms = [j for j, i in enumerate(frame_patoms) if j not in flat_groups]\n",
    "    \n",
    "    # remaining patoms plus grouped patoms need to be compared against reference tables or else stored in new table \n",
    "    patom_index_list = similar_pattern_groups_list_new + remaining_patoms\n",
    "    \n",
    "    #############################################################################################################################################################\n",
    "    ########## THIRD TASK: STORE NEW PATTERNS IN EMPTY TABLES AND ADD OLD (PATTERNS SIMILAR TO PREVIOUSLY RECEIVED DATA) IN THEIR RESPECTIVE TABLES #############\n",
    "    #############################################################################################################################################################\n",
    "    ## get all non-empty reference data tables from the database\n",
    "    ref = nonref = cur2d.execute(\"select name from (SELECT name, count(*) as rc FROM sqlite_master WHERE type='table' AND name NOT LIKE '%ref%' group by name) where rc > 0;\")\n",
    "    tables_ref = ref.fetchall()  # List of tuples with table names\n",
    "    # if there are non-empty reference tables then loop through tables and compare reference pattern against newly acquired patterns\n",
    "    if tables_ref:\n",
    "        similar_pattern_groups_list_ref = []\n",
    "        table_names_ref = []\n",
    "        for (ref_name,) in tables_ref:\n",
    "            table_names_ref.append(ref_name)\n",
    "        # compare new patterns against existing reference patterns, if patterns do not match ref pattern store in new table\n",
    "        patom_ref_indexes = list(product(range(num_patoms), range(len(table_names_ref))))\n",
    "        with Pool(processes=cpu_count()) as pool:\n",
    "            items = [(frame_patoms[i[0]][0], frame_patoms[i[0]][1], table_names_ref[i[1]][0], table_names_ref[i[1]][1]) for i in patom_ref_indexes]\n",
    "            ## function outputs ind value of the patom_indexes list, the centroid and distance similarity measures\n",
    "            res = pool.starmap(pattern_compare_2d, items)\n",
    "            # res output: [1.0, (0.05407046509274386, 0.03361332388786884)]\n",
    "            #print(\"Time to compare 2D patterns with multiprocessing (secs):\", (perf_counter()-atime))\n",
    "            # create list the holds the index of each patom identified in the frame that are similar to one another\n",
    "            match_list_ref = []\n",
    "            ## loop through the output of the comparison function\n",
    "            for ix, i in enumerate(res):\n",
    "                ## pass if its the same patom in the frame being compared against itself\n",
    "                if patom_ref_indexes[ix][0] == patom_ref_indexes[ix][1]:\n",
    "                    pass\n",
    "                else:\n",
    "                    ## check if compared patterns fall within similarity threshold values\n",
    "                    if (i[1][0] >= centroid_sim_threshold_x) and (i[1][1] >= centroid_sim_threshold_y) and (i[0] >= dist_sim_threshold):\n",
    "                        match_list_ref.append([patom_indexes[ix][0], patom_indexes[ix][1]])\n",
    "                    else:\n",
    "                        pass\n",
    "            # merge pattern indices that have similar elements\n",
    "            if match_list_ref:\n",
    "                similar_pattern_groups = merge_lists_with_common_elements(match_list_ref)\n",
    "                similar_pattern_groups_list_ref.append(similar_pattern_groups)\n",
    "            \n",
    "    # if there are no non-empty reference tables then write patterns to new tables\n",
    "    else:\n",
    "\n",
    "    \n",
    "    ## if there is at least one non-empty reference table then we compare current patterns against reference pattern\n",
    "    # if table_names_ref:\n",
    "    #     for i in table_frame_patoms:\n",
    "    #         for j in table_names_ref:\n",
    "    #             if \n",
    "\n",
    "    ## get all non-empty non reference data tables from the database\n",
    "    # nonref = cur2d.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE '%ref%';\")\n",
    "    # tables_nonref = nonref.fetchall()  # List of tuples with table names\n",
    "    # table_names_nonref = []\n",
    "    # # Loop through each table and check if it's empty\n",
    "    # for (table_name,) in tables_nonref:  # Unpack the tuple\n",
    "    #     cur2d.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "    #     row_count = cur2d.fetchone()[0]  # Get the row count\n",
    "    #     ## perform comparison on tables that have data in the database\n",
    "    #     if row_count == 0:\n",
    "    #         table_names_nonref.append(table_name)\n",
    "    #     else:\n",
    "    #         pass\n",
    "    ## sort table names (in case they aren't)\n",
    "    #table_names_nonref = sorted(table_names_nonref)\n",
    "    \n",
    "    # ## insert data into empty tables\n",
    "    # for jx, j in enumerate(similar_pattern_groups):\n",
    "    #     # now that I have the empty table I need to write all the patterns from each pattern group into it\n",
    "    #     for patom in j:\n",
    "    #         cur2d.executemany(f\"INSERT INTO {table_names[jx]}(frame, norm_x_dist, norm_y_dist, pat_cent_x, pat_cent_y, patom_ind) VALUES (?,?,?,?,?,?,?,?)\", table_frame_patoms[patom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build function to get the average of each of the patterns in each table\n",
    "## the reference table should have the most common of x, y positions, the most common x and y centroid positions\n",
    "# ref = cur2d.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name LIKE '%ref%';\")\n",
    "# tables_ref = ref.fetchall()  # List of tuples with table names\n",
    "# # Loop through each table delete rows and re-insert new averaged values from patterns just ingested by system\n",
    "# for (ref_name,) in tables_ref:  # Unpack the tuple \n",
    "#     if ref_name.replace('_ref','') in tables_ref:\n",
    "# #         cur2d.execute(f\"DELETE FROM {ref_name};\")\n",
    "# #         cur2d.execute(f\"INSERT INTO {ref_name}(avg_norm_x_pos, avg_norm_y_pos, avg_norm_dist) \\\n",
    "# #                         SELECT AVG(norm_x_pos) AS norm_x_pos, AVG(norm_y_pos) as norm_y_pos, AVG(norm_dist) as norm_dist FROM {ref_name.replace('_ref','')}\")\n",
    "# #     else:\n",
    "# #         pass\n",
    "\n",
    "# patom = [[norm_x, norm_y], [pattern_centroid_x, pattern_centroid_y], ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all non-empty non reference data tables from the database\n",
    "# nonref = cur2d.execute(\"select name from (SELECT name, count(*) as rc FROM sqlite_master WHERE type='table' AND name NOT LIKE '%ref%' group by name) where rc > 0;\")\n",
    "# tables_nonref = nonref.fetchall()  # List of tuples with table names\n",
    "# table_names_nonref = []\n",
    "# # Loop through each table and create reference table\n",
    "# for (table_name,) in tables_nonref[0]: \n",
    "#     # ref table requires avg pat cent x, y, the avg num of rows, which consists of the most frequent x, y positions\n",
    "#     ref_table = cur2d.execute(f\"\"\"\n",
    "#                     select\n",
    "#                         *\n",
    "#                         from\n",
    "#                         (\n",
    "#                         select \n",
    "#                             patom_time, --single value\n",
    "#                             count(*) over() as rc, \n",
    "#                             pat_cent_x, --single value\n",
    "#                             pat_cent_y, -- single value\n",
    "#                             norm_x_dist, -- not sure if this is list of single values entered in rows\n",
    "#                             count(round(norm_x_dist,4)) over() as x_dist_freq, \n",
    "#                             norm_y_dist,\n",
    "#                             count(round(norm_y_dist,4)) over() as y_dist_freq\n",
    "                                \n",
    "#                             from {table_name}\n",
    "#                         ) as bse\n",
    "                        \n",
    "#                     ;\"\"\")\n",
    "        \n",
    "# patom = [[norm_x, norm_y], [pattern_centroid_x, pattern_centroid_y], ind, f_ind, patom_time]\n",
    "# ## sort table names (in case they aren't)\n",
    "# table_names_nonref = sorted(table_names_nonref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con2d.commit()\n",
    "# con2d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rough work ###\n",
    "#     compare_list = []\n",
    "# # Initialize an empty dictionary\n",
    "#         result_dict = {}\n",
    "#         # Iterate over the list of lists\n",
    "#         for key, value in match_list:\n",
    "#             # Add the value to the appropriate key in the dictionary\n",
    "#             if key not in result_dict:\n",
    "#                 result_dict[key] = []\n",
    "#             result_dict[key].append(value)\n",
    "#         compare_list.append(result_dict)\n",
    "\n",
    "## function to find the next empty list in a set of nested lists\n",
    "# def find_next_empty_list_iterative(nested_list):\n",
    "#     stack = [(nested_list, [])]  # (current_list, current_path)\n",
    "\n",
    "#     while stack:\n",
    "#         current, path = stack.pop()\n",
    "#         for index, element in enumerate(current):\n",
    "#             current_path = path + [index]\n",
    "#             if element == []:\n",
    "#                 return current_path\n",
    "#             elif isinstance(element, list):\n",
    "#                 stack.append((element, current_path))\n",
    "#     return None  # No empty list found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
